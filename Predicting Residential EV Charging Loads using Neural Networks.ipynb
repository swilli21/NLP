{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Predicting Residential EV Charging Loads using Neural Networks\n",
    "\n",
    "### a model like this could be useful in predicting things like energy costs when developing EV charging infrastructure.\n",
    "\n",
    "Data : https://data.mendeley.com/datasets/jbks2rcwyj/1\n",
    "\n",
    "### Data Features\n",
    "- session_ID - the unique id for each EV charging session\n",
    "- Garage_ID - the unique id for the garage of the apartment\n",
    "- User_ID - the unique id for each user\n",
    "- User_private - 1.0 indicates private charge point spaces and 0.0 indicates shared charge point spaces\n",
    "- Shared_ID - the unique id if shared charge point spaces are used\n",
    "- Start_plugin - the plug-in date and time in the format (day.month.year hour:minute)\n",
    "- Start_plugin_hour - the plug-in date and time rounded to the start of the hour\n",
    "- End_plugout - the plug-out date and time in the format (day.month.year hour:minute)\n",
    "- End_plugout_hour - the start of the hour of the End_plugout hour\n",
    "- El_kWh - the charged energy in kWh (charging loads)\n",
    "- Duration_hours - the duration of the EV connection time per session\n",
    "- Plugin_category - the plug-in time categorized by early/late night, morning, afternoon, and evening\n",
    "- Duration_category - the plug-in duration categorized by 3 hour groups\n",
    "- month_plugin_{month} - the month of the plug-in session\n",
    "- weekdays_plugin_{day} - the day of the week of the plug-in session\n",
    "\n",
    "\n",
    "Target to predict\n",
    "\n",
    "1. the actual charging load in kilowatt hours for a charging session"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Setup - import basic data libraries\n",
    "import numpy as np\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load, Inspect, and Merge Datasets"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 1\n",
    "\n",
    "The file `'datasets/EV charging reports.csv'` contains electric vehicle (EV) charging data. These come from various residential apartment buildings in Norway. The data includes specific user and garage information, plug-in and plug-out times, charging loads, and the dates of the charging sessions.\n",
    "\n",
    "Import this CSV file to a pandas DataFrame named `ev_charging_reports`.\n",
    "\n",
    "Use the `.head()` method to preview the first five rows."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>session_ID</th>\n",
       "      <th>Garage_ID</th>\n",
       "      <th>User_ID</th>\n",
       "      <th>User_private</th>\n",
       "      <th>Shared_ID</th>\n",
       "      <th>Start_plugin</th>\n",
       "      <th>Start_plugin_hour</th>\n",
       "      <th>End_plugout</th>\n",
       "      <th>End_plugout_hour</th>\n",
       "      <th>El_kWh</th>\n",
       "      <th>...</th>\n",
       "      <th>month_plugin_Nov</th>\n",
       "      <th>month_plugin_Oct</th>\n",
       "      <th>month_plugin_Sep</th>\n",
       "      <th>weekdays_plugin_Friday</th>\n",
       "      <th>weekdays_plugin_Monday</th>\n",
       "      <th>weekdays_plugin_Saturday</th>\n",
       "      <th>weekdays_plugin_Sunday</th>\n",
       "      <th>weekdays_plugin_Thursday</th>\n",
       "      <th>weekdays_plugin_Tuesday</th>\n",
       "      <th>weekdays_plugin_Wednesday</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>AdO3</td>\n",
       "      <td>AdO3-4</td>\n",
       "      <td>1.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>21.12.2018 10:20</td>\n",
       "      <td>21.12.2018 10:00</td>\n",
       "      <td>21.12.2018 10:23</td>\n",
       "      <td>10.0</td>\n",
       "      <td>0,3</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>AdO3</td>\n",
       "      <td>AdO3-4</td>\n",
       "      <td>1.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>21.12.2018 10:24</td>\n",
       "      <td>21.12.2018 10:00</td>\n",
       "      <td>21.12.2018 10:32</td>\n",
       "      <td>10.0</td>\n",
       "      <td>0,87</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>AdO3</td>\n",
       "      <td>AdO3-4</td>\n",
       "      <td>1.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>21.12.2018 11:33</td>\n",
       "      <td>21.12.2018 11:00</td>\n",
       "      <td>21.12.2018 19:46</td>\n",
       "      <td>19.0</td>\n",
       "      <td>29,87</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>AdO3</td>\n",
       "      <td>AdO3-2</td>\n",
       "      <td>1.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>22.12.2018 16:15</td>\n",
       "      <td>22.12.2018 16:00</td>\n",
       "      <td>23.12.2018 16:40</td>\n",
       "      <td>16.0</td>\n",
       "      <td>15,56</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>AdO3</td>\n",
       "      <td>AdO3-2</td>\n",
       "      <td>1.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>24.12.2018 22:03</td>\n",
       "      <td>24.12.2018 22:00</td>\n",
       "      <td>24.12.2018 23:02</td>\n",
       "      <td>23.0</td>\n",
       "      <td>3,62</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 32 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   session_ID Garage_ID User_ID  User_private Shared_ID      Start_plugin  \\\n",
       "0           1      AdO3  AdO3-4           1.0       NaN  21.12.2018 10:20   \n",
       "1           2      AdO3  AdO3-4           1.0       NaN  21.12.2018 10:24   \n",
       "2           3      AdO3  AdO3-4           1.0       NaN  21.12.2018 11:33   \n",
       "3           4      AdO3  AdO3-2           1.0       NaN  22.12.2018 16:15   \n",
       "4           5      AdO3  AdO3-2           1.0       NaN  24.12.2018 22:03   \n",
       "\n",
       "  Start_plugin_hour       End_plugout  End_plugout_hour El_kWh  ...  \\\n",
       "0  21.12.2018 10:00  21.12.2018 10:23              10.0    0,3  ...   \n",
       "1  21.12.2018 10:00  21.12.2018 10:32              10.0   0,87  ...   \n",
       "2  21.12.2018 11:00  21.12.2018 19:46              19.0  29,87  ...   \n",
       "3  22.12.2018 16:00  23.12.2018 16:40              16.0  15,56  ...   \n",
       "4  24.12.2018 22:00  24.12.2018 23:02              23.0   3,62  ...   \n",
       "\n",
       "  month_plugin_Nov month_plugin_Oct month_plugin_Sep  weekdays_plugin_Friday  \\\n",
       "0              0.0              0.0              0.0                     1.0   \n",
       "1              0.0              0.0              0.0                     1.0   \n",
       "2              0.0              0.0              0.0                     1.0   \n",
       "3              0.0              0.0              0.0                     0.0   \n",
       "4              0.0              0.0              0.0                     0.0   \n",
       "\n",
       "   weekdays_plugin_Monday  weekdays_plugin_Saturday  weekdays_plugin_Sunday  \\\n",
       "0                     0.0                       0.0                     0.0   \n",
       "1                     0.0                       0.0                     0.0   \n",
       "2                     0.0                       0.0                     0.0   \n",
       "3                     0.0                       1.0                     0.0   \n",
       "4                     1.0                       0.0                     0.0   \n",
       "\n",
       "   weekdays_plugin_Thursday  weekdays_plugin_Tuesday  \\\n",
       "0                       0.0                      0.0   \n",
       "1                       0.0                      0.0   \n",
       "2                       0.0                      0.0   \n",
       "3                       0.0                      0.0   \n",
       "4                       0.0                      0.0   \n",
       "\n",
       "   weekdays_plugin_Wednesday  \n",
       "0                        0.0  \n",
       "1                        0.0  \n",
       "2                        0.0  \n",
       "3                        0.0  \n",
       "4                        0.0  \n",
       "\n",
       "[5 rows x 32 columns]"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ev_charging_reports = pd.read_csv(\"datasets/EV charging reports.csv\")\n",
    "ev_charging_reports.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<details><summary style=\"display:list-item; font-size:16px; color:blue;\">What is the structure of the dataset?</summary>\n",
    "\n",
    "- **session_ID** - the unique id for each EV charging session\n",
    "- **Garage_ID** - the unique id for the garage of the apartment\n",
    "- **User_ID** - the unique id for each user\n",
    "- **User_private** - 1.0 indicates private charge point spaces and 0.0 indicates shared charge point spaces\n",
    "- **Shared_ID** - the unique id if shared charge point spaces are used\n",
    "- **Start_plugin** - the plug-in date and time in the format (day.month.year hour:minute)\n",
    "- **Start_plugin_hour** - the plug-in date and time rounded to the start of the hour\n",
    "- **End_plugout** - the plug-out date and time in the format (day.month.year hour:minute)\n",
    "- **End_plugout_hour** - the start of the hour of the `End_plugout` hour\n",
    "- **El_kWh** - the charged energy in kWh (charging loads)\n",
    "- **Duration_hours** - the duration of the EV connection time per session\n",
    "- **Plugin_category** - the plug-in time categorized by early/late night, morning, afternoon, and evening\n",
    "- **Duration_category** - the plug-in duration categorized by 3 hour groups\n",
    "- **month_plugin_{month}** - the month of the plug-in session\n",
    "- **weekdays_plugin_{day}** - the day of the week of the plug-in session"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 2\n",
    "\n",
    "Import the file `'datasets/Local traffic distribution.csv'` to a pandas DataFrame named `traffic_reports`. This dataset contains the hourly local traffic density counts at 5 nearby traffic locations. \n",
    "\n",
    "Preview the first five rows."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Date_from</th>\n",
       "      <th>Date_to</th>\n",
       "      <th>Kroppan_bru_traffic</th>\n",
       "      <th>Moholtlia_traffic</th>\n",
       "      <th>Selsbakk_traffic</th>\n",
       "      <th>Moholt_rampe_2_traffic</th>\n",
       "      <th>Jonsvannsveien_vest_steinanvegen_traffic</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>01.12.2018 00:00</td>\n",
       "      <td>01.12.2018 01:00</td>\n",
       "      <td>639</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "      <td>144</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>01.12.2018 01:00</td>\n",
       "      <td>01.12.2018 02:00</td>\n",
       "      <td>487</td>\n",
       "      <td>153</td>\n",
       "      <td>115</td>\n",
       "      <td>21</td>\n",
       "      <td>83</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>01.12.2018 02:00</td>\n",
       "      <td>01.12.2018 03:00</td>\n",
       "      <td>408</td>\n",
       "      <td>85</td>\n",
       "      <td>75</td>\n",
       "      <td>10</td>\n",
       "      <td>69</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>01.12.2018 03:00</td>\n",
       "      <td>01.12.2018 04:00</td>\n",
       "      <td>282</td>\n",
       "      <td>89</td>\n",
       "      <td>56</td>\n",
       "      <td>8</td>\n",
       "      <td>39</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>01.12.2018 04:00</td>\n",
       "      <td>01.12.2018 05:00</td>\n",
       "      <td>165</td>\n",
       "      <td>64</td>\n",
       "      <td>34</td>\n",
       "      <td>3</td>\n",
       "      <td>25</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "          Date_from           Date_to  Kroppan_bru_traffic  Moholtlia_traffic  \\\n",
       "0  01.12.2018 00:00  01.12.2018 01:00                  639                  0   \n",
       "1  01.12.2018 01:00  01.12.2018 02:00                  487                153   \n",
       "2  01.12.2018 02:00  01.12.2018 03:00                  408                 85   \n",
       "3  01.12.2018 03:00  01.12.2018 04:00                  282                 89   \n",
       "4  01.12.2018 04:00  01.12.2018 05:00                  165                 64   \n",
       "\n",
       "   Selsbakk_traffic  Moholt_rampe_2_traffic  \\\n",
       "0                 0                       4   \n",
       "1               115                      21   \n",
       "2                75                      10   \n",
       "3                56                       8   \n",
       "4                34                       3   \n",
       "\n",
       "   Jonsvannsveien_vest_steinanvegen_traffic  \n",
       "0                                       144  \n",
       "1                                        83  \n",
       "2                                        69  \n",
       "3                                        39  \n",
       "4                                        25  "
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "traffic_reports = pd.read_csv('datasets/Local traffic distribution.csv')\n",
    "traffic_reports.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<details><summary style=\"display:list-item; font-size:16px; color:blue;\">What is the structure of the dataset?</summary>\n",
    "\n",
    "- **Date_from** - the starting time in the format (day.month.year hour:minute)\n",
    "- **Date_to** - the ending time in the format (day.month.year hour:minute)\n",
    "- **Location 1 to 5** - contains the number of vehicles each hour at a specified traffic location.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 3\n",
    "\n",
    "We'd like to use the traffic data to help our model. The same charging location may charge at different rates depending on the number of cars being charged, so this traffic data might help the model out.\n",
    "\n",
    "Merge the `ev_charging_reports` and `traffic_reports` datasets together into a Dataframe named `ev_charging_traffic` using the columns:\n",
    "\n",
    "- `Start_plugin_hour` in `ev_charging_reports`\n",
    "- `Date_from` in `traffic_reports`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>session_ID</th>\n",
       "      <th>Garage_ID</th>\n",
       "      <th>User_ID</th>\n",
       "      <th>User_private</th>\n",
       "      <th>Shared_ID</th>\n",
       "      <th>Start_plugin</th>\n",
       "      <th>Start_plugin_hour</th>\n",
       "      <th>End_plugout</th>\n",
       "      <th>End_plugout_hour</th>\n",
       "      <th>El_kWh</th>\n",
       "      <th>...</th>\n",
       "      <th>weekdays_plugin_Thursday</th>\n",
       "      <th>weekdays_plugin_Tuesday</th>\n",
       "      <th>weekdays_plugin_Wednesday</th>\n",
       "      <th>Date_from</th>\n",
       "      <th>Date_to</th>\n",
       "      <th>Kroppan_bru_traffic</th>\n",
       "      <th>Moholtlia_traffic</th>\n",
       "      <th>Selsbakk_traffic</th>\n",
       "      <th>Moholt_rampe_2_traffic</th>\n",
       "      <th>Jonsvannsveien_vest_steinanvegen_traffic</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>AdO3</td>\n",
       "      <td>AdO3-4</td>\n",
       "      <td>1.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>21.12.2018 10:20</td>\n",
       "      <td>21.12.2018 10:00</td>\n",
       "      <td>21.12.2018 10:23</td>\n",
       "      <td>10.0</td>\n",
       "      <td>0,3</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>21.12.2018 10:00</td>\n",
       "      <td>21.12.2018 11:00</td>\n",
       "      <td>3244</td>\n",
       "      <td>1632</td>\n",
       "      <td>545</td>\n",
       "      <td>194</td>\n",
       "      <td>622</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>AdO3</td>\n",
       "      <td>AdO3-4</td>\n",
       "      <td>1.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>21.12.2018 10:24</td>\n",
       "      <td>21.12.2018 10:00</td>\n",
       "      <td>21.12.2018 10:32</td>\n",
       "      <td>10.0</td>\n",
       "      <td>0,87</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>21.12.2018 10:00</td>\n",
       "      <td>21.12.2018 11:00</td>\n",
       "      <td>3244</td>\n",
       "      <td>1632</td>\n",
       "      <td>545</td>\n",
       "      <td>194</td>\n",
       "      <td>622</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>AdO3</td>\n",
       "      <td>AdO3-4</td>\n",
       "      <td>1.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>21.12.2018 11:33</td>\n",
       "      <td>21.12.2018 11:00</td>\n",
       "      <td>21.12.2018 19:46</td>\n",
       "      <td>19.0</td>\n",
       "      <td>29,87</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>21.12.2018 11:00</td>\n",
       "      <td>21.12.2018 12:00</td>\n",
       "      <td>3605</td>\n",
       "      <td>1691</td>\n",
       "      <td>605</td>\n",
       "      <td>230</td>\n",
       "      <td>771</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>AdO3</td>\n",
       "      <td>AdO3-2</td>\n",
       "      <td>1.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>22.12.2018 16:15</td>\n",
       "      <td>22.12.2018 16:00</td>\n",
       "      <td>23.12.2018 16:40</td>\n",
       "      <td>16.0</td>\n",
       "      <td>15,56</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>22.12.2018 16:00</td>\n",
       "      <td>22.12.2018 17:00</td>\n",
       "      <td>3052</td>\n",
       "      <td>1484</td>\n",
       "      <td>453</td>\n",
       "      <td>224</td>\n",
       "      <td>694</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>AdO3</td>\n",
       "      <td>AdO3-2</td>\n",
       "      <td>1.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>24.12.2018 22:03</td>\n",
       "      <td>24.12.2018 22:00</td>\n",
       "      <td>24.12.2018 23:02</td>\n",
       "      <td>23.0</td>\n",
       "      <td>3,62</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>24.12.2018 22:00</td>\n",
       "      <td>24.12.2018 23:00</td>\n",
       "      <td>1390</td>\n",
       "      <td>693</td>\n",
       "      <td>226</td>\n",
       "      <td>83</td>\n",
       "      <td>353</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 39 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   session_ID Garage_ID User_ID  User_private Shared_ID      Start_plugin  \\\n",
       "0           1      AdO3  AdO3-4           1.0       NaN  21.12.2018 10:20   \n",
       "1           2      AdO3  AdO3-4           1.0       NaN  21.12.2018 10:24   \n",
       "2           3      AdO3  AdO3-4           1.0       NaN  21.12.2018 11:33   \n",
       "3           4      AdO3  AdO3-2           1.0       NaN  22.12.2018 16:15   \n",
       "4           5      AdO3  AdO3-2           1.0       NaN  24.12.2018 22:03   \n",
       "\n",
       "  Start_plugin_hour       End_plugout  End_plugout_hour El_kWh  ...  \\\n",
       "0  21.12.2018 10:00  21.12.2018 10:23              10.0    0,3  ...   \n",
       "1  21.12.2018 10:00  21.12.2018 10:32              10.0   0,87  ...   \n",
       "2  21.12.2018 11:00  21.12.2018 19:46              19.0  29,87  ...   \n",
       "3  22.12.2018 16:00  23.12.2018 16:40              16.0  15,56  ...   \n",
       "4  24.12.2018 22:00  24.12.2018 23:02              23.0   3,62  ...   \n",
       "\n",
       "  weekdays_plugin_Thursday weekdays_plugin_Tuesday weekdays_plugin_Wednesday  \\\n",
       "0                      0.0                     0.0                       0.0   \n",
       "1                      0.0                     0.0                       0.0   \n",
       "2                      0.0                     0.0                       0.0   \n",
       "3                      0.0                     0.0                       0.0   \n",
       "4                      0.0                     0.0                       0.0   \n",
       "\n",
       "          Date_from           Date_to  Kroppan_bru_traffic  Moholtlia_traffic  \\\n",
       "0  21.12.2018 10:00  21.12.2018 11:00                 3244               1632   \n",
       "1  21.12.2018 10:00  21.12.2018 11:00                 3244               1632   \n",
       "2  21.12.2018 11:00  21.12.2018 12:00                 3605               1691   \n",
       "3  22.12.2018 16:00  22.12.2018 17:00                 3052               1484   \n",
       "4  24.12.2018 22:00  24.12.2018 23:00                 1390                693   \n",
       "\n",
       "   Selsbakk_traffic  Moholt_rampe_2_traffic  \\\n",
       "0               545                     194   \n",
       "1               545                     194   \n",
       "2               605                     230   \n",
       "3               453                     224   \n",
       "4               226                      83   \n",
       "\n",
       "   Jonsvannsveien_vest_steinanvegen_traffic  \n",
       "0                                       622  \n",
       "1                                       622  \n",
       "2                                       771  \n",
       "3                                       694  \n",
       "4                                       353  \n",
       "\n",
       "[5 rows x 39 columns]"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ev_charging_traffic = pd.merge(ev_charging_reports, traffic_reports, left_on='Start_plugin_hour', right_on='Date_from')\n",
    "ev_charging_traffic.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Task 4\n",
    "\n",
    "Use `.info()` to inspect the merged dataset. Specifically, pay attention to the data types and number of missing values in each column."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 6833 entries, 0 to 6832\n",
      "Data columns (total 39 columns):\n",
      " #   Column                                    Non-Null Count  Dtype  \n",
      "---  ------                                    --------------  -----  \n",
      " 0   session_ID                                6833 non-null   int64  \n",
      " 1   Garage_ID                                 6833 non-null   object \n",
      " 2   User_ID                                   6833 non-null   object \n",
      " 3   User_private                              6833 non-null   float64\n",
      " 4   Shared_ID                                 1399 non-null   object \n",
      " 5   Start_plugin                              6833 non-null   object \n",
      " 6   Start_plugin_hour                         6833 non-null   object \n",
      " 7   End_plugout                               6833 non-null   object \n",
      " 8   End_plugout_hour                          6833 non-null   float64\n",
      " 9   El_kWh                                    6833 non-null   object \n",
      " 10  Duration_hours                            6833 non-null   object \n",
      " 11  Plugin_category                           6833 non-null   object \n",
      " 12  Duration_category                         6833 non-null   object \n",
      " 13  month_plugin_Apr                          6833 non-null   float64\n",
      " 14  month_plugin_Aug                          6833 non-null   float64\n",
      " 15  month_plugin_Dec                          6833 non-null   float64\n",
      " 16  month_plugin_Feb                          6833 non-null   float64\n",
      " 17  month_plugin_Jan                          6833 non-null   float64\n",
      " 18  month_plugin_Jul                          6833 non-null   float64\n",
      " 19  month_plugin_Jun                          6833 non-null   float64\n",
      " 20  month_plugin_Mar                          6833 non-null   float64\n",
      " 21  month_plugin_May                          6833 non-null   float64\n",
      " 22  month_plugin_Nov                          6833 non-null   float64\n",
      " 23  month_plugin_Oct                          6833 non-null   float64\n",
      " 24  month_plugin_Sep                          6833 non-null   float64\n",
      " 25  weekdays_plugin_Friday                    6833 non-null   float64\n",
      " 26  weekdays_plugin_Monday                    6833 non-null   float64\n",
      " 27  weekdays_plugin_Saturday                  6833 non-null   float64\n",
      " 28  weekdays_plugin_Sunday                    6833 non-null   float64\n",
      " 29  weekdays_plugin_Thursday                  6833 non-null   float64\n",
      " 30  weekdays_plugin_Tuesday                   6833 non-null   float64\n",
      " 31  weekdays_plugin_Wednesday                 6833 non-null   float64\n",
      " 32  Date_from                                 6833 non-null   object \n",
      " 33  Date_to                                   6833 non-null   object \n",
      " 34  Kroppan_bru_traffic                       6833 non-null   int64  \n",
      " 35  Moholtlia_traffic                         6833 non-null   int64  \n",
      " 36  Selsbakk_traffic                          6833 non-null   int64  \n",
      " 37  Moholt_rampe_2_traffic                    6833 non-null   int64  \n",
      " 38  Jonsvannsveien_vest_steinanvegen_traffic  6833 non-null   int64  \n",
      "dtypes: float64(21), int64(6), object(12)\n",
      "memory usage: 2.0+ MB\n"
     ]
    }
   ],
   "source": [
    "ev_charging_traffic.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<details><summary style=\"display:list-item; font-size:16px; color:blue;\">What do we notice about merged dataset under inspection?</summary>\n",
    "\n",
    "We see that there are 39 columns and 6,833 rows in our merged dataset.\n",
    "\n",
    "Some notable things we might have to address:\n",
    "\n",
    "- We expected columns like `El_kWh` and `Duration_hours` to be floats but they are actually object data types.\n",
    "\n",
    "- There are many identifying columns like `session_ID` and `User_ID` that might not be useful for training."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##  Data Cleaning and Preparation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 5\n",
    "\n",
    "Let's start by reducing the size of our dataset by dropping columns that won't be used for training. These include\n",
    "- ID columns\n",
    "- columns with lots of missing data\n",
    "- non-numeric columns (for now, since we haven't yet covered using non-numeric data in neural networks)\n",
    "\n",
    "Drop columns you don't want to use in training from `ev_charging_traffic`.\n",
    "\n",
    "To match our solution, drop the columns\n",
    "\n",
    "```py\n",
    "['session_ID', 'Garage_ID', 'User_ID', \n",
    "                'Shared_ID',\n",
    "                'Plugin_category','Duration_category', \n",
    "                'Start_plugin', 'Start_plugin_hour', 'End_plugout', 'End_plugout_hour', \n",
    "                'Date_from', 'Date_to']\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "ev_charging_traffic = ev_charging_traffic.drop(['session_ID', 'Garage_ID', 'User_ID', 'Shared_ID', 'Plugin_category', 'Duration_category', 'Start_plugin', 'Start_plugin_hour', 'End_plugout', 'End_plugout_hour', 'Date_from', 'Date_to'], axis=1)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 6\n",
    "\n",
    "Earlier we saw that the `El_kWh` and `Duration_hours` columns were object data types. Upon further inspection, we see that the reason is that the data is following European notation where commas `,` are used as decimals instead of periods.\n",
    "\n",
    "Replace `,` with `.` in these three columns."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "ev_charging_traffic['El_kWh'] = ev_charging_traffic['El_kWh'].str.replace(',','.')\n",
    "ev_charging_traffic['Duration_hours'] = ev_charging_traffic['Duration_hours'].str.replace(',','.')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 7\n",
    "\n",
    "Next, convert the data types of all the columns of `ev_charging_traffic` to floats."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "ev_charging_traffic = ev_charging_traffic.astype(float)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Train Test Split\n",
    "\n",
    "Next, let's split the dataset into training and testing datasets. \n",
    "\n",
    "The training data will be used to train the model and the testing data will be used to evaluate the model."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 8\n",
    "\n",
    "First, create two datasets from `ev_charging_traffic`:\n",
    "\n",
    "- `X` contains only the input numerical features\n",
    "- `y` contains only the target column `El_kWh`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "X = ev_charging_traffic.drop('El_kWh', axis=1)\n",
    "y = ev_charging_traffic['El_kWh']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 9\n",
    "\n",
    "Use `sklearn` to split `X` and `y` into training and testing datasets. The training set should use 80% of the data. Set the `random_state` parameter to `2`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X, y,\n",
    "    train_size=0.80,\n",
    "    test_size=0.20,\n",
    "    random_state=2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Linear Regression Baseline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This section is optional, but useful. The idea is to compare our neural network to a basic linear regression. After all, if a basic linear regression works just as well, there's no need for the neural network!\n",
    "\n",
    "If you haven't done linear regression with scikit-learn before, feel free to use [our solution code](./solutions.html) or to skip ahead."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 10\n",
    "\n",
    "Use Scikit-learn to train a Linear Regression model using the training data to predict EV charging loads.\n",
    "\n",
    "The linear regression will be used as a baseline to compare against the neural network we will train later."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>#sk-container-id-1 {color: black;}#sk-container-id-1 pre{padding: 0;}#sk-container-id-1 div.sk-toggleable {background-color: white;}#sk-container-id-1 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-1 label.sk-toggleable__label-arrow:before {content: \"▸\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-1 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-1 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-1 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-1 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-1 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-1 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"▾\";}#sk-container-id-1 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-1 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-1 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-1 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-1 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-1 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-1 div.sk-item {position: relative;z-index: 1;}#sk-container-id-1 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-1 div.sk-item::before, #sk-container-id-1 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-1 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-1 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-1 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-1 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-1 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-1 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-1 div.sk-label-container {text-align: center;}#sk-container-id-1 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-1 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-1\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>LinearRegression()</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-1\" type=\"checkbox\" checked><label for=\"sk-estimator-id-1\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">LinearRegression</label><div class=\"sk-toggleable__content\"><pre>LinearRegression()</pre></div></div></div></div></div>"
      ],
      "text/plain": [
       "LinearRegression()"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.linear_model import LinearRegression\n",
    "\n",
    "linear_model = LinearRegression()\n",
    "linear_model.fit(X_train, y_train)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 11\n",
    "\n",
    "Evaluate the linear regression baseline by calculating the MSE on the testing data. Use `mean_squared_error` from `sklearn.metrics`.\n",
    "\n",
    "Save the testing MSE to the variable `test_mse` and print it out."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The mean squared error is: 131.4188163356643\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import mean_squared_error\n",
    "\n",
    "predictions = linear_model.predict(X_test)\n",
    "\n",
    "test_mse = mean_squared_error(y_test, predictions)\n",
    "print(f\"The mean squared error is: {test_mse}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Looks like our mean squared error is around `131.4` (if you used different columns in your model than we did, you might have a different value). Remember, this is squared error. If we take the square root, we have about `11.5`. One way of interpreting this is to say that the linear regression, on average, is off by `11.5 kWh`."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Train a Neural Network Using PyTorch\n",
    "\n",
    "Let's now create a neural network using PyTorch to predict EV charging loads."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Task 12\n",
    "\n",
    "First, we'll need to import the PyTorch library and modules.\n",
    "\n",
    "Import the PyTorch library `torch`.\n",
    "\n",
    "From `torch`, import `nn` to access built-in code for constructing networks and defining loss functions.\n",
    "\n",
    "From `torch`, import `optim` to access built-in optimizer algorithms."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 13\n",
    "\n",
    "Before training the neural network, convert the training and testing sets into PyTorch tensors and specify `float` as the data type for the values."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Use the .view(-1, 1) method to reshape the y_train and y_test tensors for training.\n",
    "X_train_tensor = torch.tensor(X_train.values, dtype=torch.float32)\n",
    "X_test_tensor = torch.tensor(X_test.values, dtype=torch.float32)\n",
    "y_train_tensor = torch.tensor(y_train.values, dtype=torch.float32).view(-1,1)\n",
    "y_test_tensor = torch.tensor(y_test.values, dtype=torch.float32).view(-1,1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 14\n",
    "\n",
    "Next, let's use `nn.Sequential` to create a neural network.\n",
    "\n",
    "First, set a random seed using `torch.manual_seed(42)`.\n",
    "\n",
    "Then, create a sequential neural network with the following architecture:\n",
    "\n",
    "- input layer with number of nodes equal to the number of training features\n",
    "- a first hidden layer with `56` nodes and a ReLU activation\n",
    "- a second hidden layer with `26` nodes and a ReLU activation\n",
    "- an output layer with `1` node\n",
    "\n",
    "Save the network to the variable `model`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Index: 5466 entries, 839 to 2575\n",
      "Data columns (total 26 columns):\n",
      " #   Column                                    Non-Null Count  Dtype  \n",
      "---  ------                                    --------------  -----  \n",
      " 0   User_private                              5466 non-null   float64\n",
      " 1   Duration_hours                            5466 non-null   float64\n",
      " 2   month_plugin_Apr                          5466 non-null   float64\n",
      " 3   month_plugin_Aug                          5466 non-null   float64\n",
      " 4   month_plugin_Dec                          5466 non-null   float64\n",
      " 5   month_plugin_Feb                          5466 non-null   float64\n",
      " 6   month_plugin_Jan                          5466 non-null   float64\n",
      " 7   month_plugin_Jul                          5466 non-null   float64\n",
      " 8   month_plugin_Jun                          5466 non-null   float64\n",
      " 9   month_plugin_Mar                          5466 non-null   float64\n",
      " 10  month_plugin_May                          5466 non-null   float64\n",
      " 11  month_plugin_Nov                          5466 non-null   float64\n",
      " 12  month_plugin_Oct                          5466 non-null   float64\n",
      " 13  month_plugin_Sep                          5466 non-null   float64\n",
      " 14  weekdays_plugin_Friday                    5466 non-null   float64\n",
      " 15  weekdays_plugin_Monday                    5466 non-null   float64\n",
      " 16  weekdays_plugin_Saturday                  5466 non-null   float64\n",
      " 17  weekdays_plugin_Sunday                    5466 non-null   float64\n",
      " 18  weekdays_plugin_Thursday                  5466 non-null   float64\n",
      " 19  weekdays_plugin_Tuesday                   5466 non-null   float64\n",
      " 20  weekdays_plugin_Wednesday                 5466 non-null   float64\n",
      " 21  Kroppan_bru_traffic                       5466 non-null   float64\n",
      " 22  Moholtlia_traffic                         5466 non-null   float64\n",
      " 23  Selsbakk_traffic                          5466 non-null   float64\n",
      " 24  Moholt_rampe_2_traffic                    5466 non-null   float64\n",
      " 25  Jonsvannsveien_vest_steinanvegen_traffic  5466 non-null   float64\n",
      "dtypes: float64(26)\n",
      "memory usage: 1.1 MB\n"
     ]
    }
   ],
   "source": [
    "X_train.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.manual_seed(42)\n",
    "\n",
    "# create neural network\n",
    "model = nn.Sequential(\n",
    "    nn.Linear(26,56),\n",
    "    nn.ReLU(),\n",
    "    nn.Linear(56,26),\n",
    "    nn.ReLU(),\n",
    "    nn.Linear(26,1)\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 15\n",
    "\n",
    "Next, let's define the loss function and optimizer used for training:\n",
    "\n",
    "- set the MSE loss function to the variable `loss`\n",
    "- set the Adam optimizer to the variable `optimizer` with a learning rate of `0.0007`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "optimizer = optim.Adam(model.parameters(), lr=0.0007)\n",
    "\n",
    "# define the loss function and compute loss\n",
    "loss = nn.MSELoss()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 16\n",
    "\n",
    "Create a training loop to train our neural network for 3000 epochs.\n",
    "\n",
    "Keep track of the training loss by printing out the MSE every 500 epochs."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [500/3000], MSE Loss: 146.96762084960938\n",
      "Epoch [1000/3000], MSE Loss: 138.64056396484375\n",
      "Epoch [1500/3000], MSE Loss: 138.99111938476562\n",
      "Epoch [2000/3000], MSE Loss: 137.61985778808594\n",
      "Epoch [2500/3000], MSE Loss: 138.0702667236328\n",
      "Epoch [3000/3000], MSE Loss: 137.82913208007812\n"
     ]
    }
   ],
   "source": [
    "num_epochs = 3000\n",
    "for epoch in range(num_epochs):\n",
    "    predictions = model(X_train_tensor) \n",
    "    MSE = loss(predictions, y_train_tensor)\n",
    "    MSE.backward()\n",
    "    optimizer.step()\n",
    "    optimizer.zero_grad()\n",
    "\n",
    "    # keep track of the loss during training\n",
    "    if (epoch + 1) % 500 == 0:\n",
    "        print(f'Epoch [{epoch + 1}/{num_epochs}], MSE Loss: {MSE.item()}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 17\n",
    "\n",
    "Save the neural network in the `models` directory using the path `models/model.pth`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "# save the neural network to a specified path\n",
    "torch.save(model, 'models/model.pth')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 18\n",
    "\n",
    "Evaluate the neural network on the testing set. \n",
    "\n",
    "Save the testing data loss to the variable `test_loss` and use `.item()` to extract and print out the loss. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test MSE is 156.2063751220703\n",
      "Test Root MSE is 12.498254883065488\n"
     ]
    }
   ],
   "source": [
    "model.eval()\n",
    "with torch.no_grad():\n",
    "    predictions = model(X_test_tensor)\n",
    "    test_MSE = loss(predictions, y_test_tensor)\n",
    "    \n",
    "print('Test MSE is ' + str(test_MSE.item()))\n",
    "print('Test Root MSE is ' + str(test_MSE.item()**(1/2)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 19\n",
    "\n",
    "We trained this same model for 4500 epochs locally. That model is saved as `models/model4500.pth`. Load this model using PyTorch and evaluate it. How well does the longer-trained model perform?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test MSE is 115.21600341796875\n",
      "Test Root MSE is 10.733871781327032\n"
     ]
    }
   ],
   "source": [
    "loaded_model = torch.load('models/model4500.pth')\n",
    "loaded_model.eval()\n",
    "with torch.no_grad():\n",
    "    predictions = loaded_model(X_test_tensor)\n",
    "    test_MSE = loss(predictions, y_test_tensor)\n",
    "\n",
    "## DO NOT MODIFY ##\n",
    "# show output\n",
    "print('Test MSE is ' + str(test_MSE.item()))\n",
    "print('Test Root MSE is ' + str(test_MSE.item()**(1/2)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Pretty cool! The increased training improved our test loss to about `115.2`, a full `12%` improvement on our linear regression baseline. So the nonlinearity introduced by the neural network actually helped us out."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "That's the end of our project on predicting EV charging loads! Feel free to continue experimenting with this neural network model. \n",
    "\n",
    "Some things you might want to investigate further include:\n",
    "- explore different ways to clean and prepare the data\n",
    "- we added traffic data, but there's no guarantee that more data converts to a better model. Test out different sets of input columns.\n",
    "- test out different number of nodes in the hidden layers, activation functions, and learning rates\n",
    "- train on a larger number of epochs "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
